{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Gambit with OpenSpiel\n",
    "\n",
    "This tutorial demonstrates the interoperability of the Gambit and OpenSpiel Python packages for game-theoretic analysis.\n",
    "\n",
    "Where Gambit is used to compute exact equilibria for games, OpenSpiel provides a variety of iterative learning algorithms that can be used to approximate strategies. Another key distinction is that the PyGambit API allows the user a simple way to define custom games (see tutorials 1-3), while OpenSpiel provides a large library of built-in games (see the [OpenSpiel documentation](https://openspiel.readthedocs.io/en/latest/games.html)).\n",
    "\n",
    "This tutorial demonstrates:\n",
    "\n",
    "1. Loading examples of normal (strategic) form and extensive form games from the OpenSpiel library into Gambit\n",
    "2. Training agents in OpenSpiel to play games and create strategies\n",
    "3. Comparing the strategies of agents trained in OpenSpiel against equilibria strategies computed with Gambit\n",
    "\n",
    "Note:\n",
    "- The version of OpenSpiel used in this tutorial is `1.6.1`. If you are running this tutorial locally, this will be the version installed via the included `requirements.txt` file.\n",
    "- You can find an introductory tutorial for the OpenSpiel API on colab [here](https://colab.research.google.com/github/deepmind/open_spiel/blob/master/open_spiel/colabs/OpenSpielTutorial.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ebb78322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import numpy as np\n",
    "\n",
    "from open_spiel.python import rl_environment\n",
    "from open_spiel.python.algorithms import tabular_qlearner\n",
    "from open_spiel.python.algorithms.gambit import export_gambit\n",
    "from open_spiel.python.egt import dynamics\n",
    "from open_spiel.python.egt.utils import game_payoffs_array\n",
    "\n",
    "import pyspiel\n",
    "\n",
    "import pygambit as gbt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd324814",
   "metadata": {},
   "source": [
    "## OpenSpiel game library\n",
    "\n",
    "The [library of games](https://openspiel.readthedocs.io/en/latest/games.html) included in OpenSpiel is extensive. Many of these games will not be amenable to equilibrium computation with Gambit, due to their size. For the purposes of this tutorial, we'll pick two smaller games from the list below, one normal form and one extensive form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3eb3671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2048', 'add_noise', 'amazons', 'backgammon', 'bargaining', 'battleship', 'blackjack', 'blotto', 'breakthrough', 'bridge', 'bridge_uncontested_bidding', 'cached_tree', 'catch', 'checkers', 'chess', 'cliff_walking', 'clobber', 'coin_game', 'colored_trails', 'connect_four', 'coop_box_pushing', 'coop_to_1p', 'coordinated_mp', 'crazy_eights', 'cribbage', 'cursor_go', 'dark_chess', 'dark_hex', 'dark_hex_ir', 'deep_sea', 'dots_and_boxes', 'dou_dizhu', 'efg_game', 'einstein_wurfelt_nicht', 'euchre', 'first_sealed_auction', 'gin_rummy', 'go', 'goofspiel', 'hanabi', 'havannah', 'hearts', 'hex', 'hive', 'kriegspiel', 'kuhn_poker', 'laser_tag', 'leduc_poker', 'lewis_signaling', 'liars_dice', 'liars_dice_ir', 'lines_of_action', 'maedn', 'mancala', 'markov_soccer', 'matching_pennies_3p', 'matrix_bos', 'matrix_brps', 'matrix_cd', 'matrix_coordination', 'matrix_mp', 'matrix_pd', 'matrix_rps', 'matrix_rpsw', 'matrix_sh', 'matrix_shapleys_game', 'mfg_crowd_modelling', 'mfg_crowd_modelling_2d', 'mfg_dynamic_routing', 'mfg_garnet', 'misere', 'mnk', 'morpion_solitaire', 'negotiation', 'nfg_game', 'nim', 'nine_mens_morris', 'normal_form_extensive_game', 'oh_hell', 'oshi_zumo', 'othello', 'oware', 'pathfinding', 'pentago', 'phantom_go', 'phantom_ttt', 'phantom_ttt_ir', 'pig', 'quoridor', 'rbc', 'repeated_game', 'restricted_nash_response', 'sheriff', 'skat', 'solitaire', 'spades', 'start_at', 'stones_and_gems', 'tarok', 'tic_tac_toe', 'tiny_bridge_2p', 'tiny_bridge_4p', 'tiny_hanabi', 'trade_comm', 'turn_based_simultaneous_game', 'twixt', 'ultimate_tic_tac_toe', 'universal_poker', 'y', 'zerosum']\n"
     ]
    }
   ],
   "source": [
    "print(pyspiel.registered_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d68403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspiel.create_matrix_game()\n",
    "# pyspiel.create_repeated_game()\n",
    "# pyspiel.create_tensor_game()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e628a86d",
   "metadata": {},
   "source": [
    "## Normal form example\n",
    "\n",
    "Let's start with a simple normal form game of rock-paper-scissors, in which the payoffs can be represented by a 3x3 matrix.\n",
    "\n",
    "Load matrix rock-paper-scissors from OpenSpiel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops_matrix_rps_game = pyspiel.load_game(\"matrix_rps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a532321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal-form games are 1-step simultaneous-move games.\n",
    "# print(state.current_player())    # special player id \n",
    "# print(state.legal_actions(0))    # query legal actions for each player\n",
    "# print(state.legal_actions(1))\n",
    "# print(state.is_terminal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f5fa4e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NFG 1 R \"OpenSpiel export of matrix_rps()\"\\n{ \"Player 0\" \"Player 1\" } { 3 3 }\\n\\n0 0\\n1 -1\\n-1 1\\n-1 1\\n0 0\\n1 -1\\n1 -1\\n-1 1\\n0 0\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfg_matrix_rps_game = pyspiel.game_to_nfg_string(ops_matrix_rps_game)\n",
    "nfg_matrix_rps_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b684325e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<center><h1>OpenSpiel export of matrix_rps()</h1></center>\n",
       "<table><tr><td></td><td align=center><b>Rock</b></td><td align=center><b>Paper</b></td><td align=center><b>Scissors</b></td></tr><tr><td align=center><b>Rock</b></td><td align=center>0,0</td><td align=center>-1,1</td><td align=center>1,-1</td></tr><tr><td align=center><b>Paper</b></td><td align=center>1,-1</td><td align=center>0,0</td><td align=center>-1,1</td></tr><tr><td align=center><b>Scissors</b></td><td align=center>-1,1</td><td align=center>1,-1</td><td align=center>0,0</td></tr></table>\n"
      ],
      "text/plain": [
       "Game(title='OpenSpiel export of matrix_rps()')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbt_matrix_rps_game = gbt.read_nfg(StringIO(nfg_matrix_rps_game))\n",
    "\n",
    "# Add labels to the strategies\n",
    "for player in gbt_matrix_rps_game.players:\n",
    "    player.strategies[0].label = \"Rock\"\n",
    "    player.strategies[1].label = \"Paper\"\n",
    "    player.strategies[2].label = \"Scissors\"\n",
    "\n",
    "gbt_matrix_rps_game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7da6f3",
   "metadata": {},
   "source": [
    "The equilibrium strategy for both players is to choose rock, paper, and scissors with equal probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "707c6c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\left[\\left[\\frac{1}{3},\\frac{1}{3},\\frac{1}{3}\\right],\\left[\\frac{1}{3},\\frac{1}{3},\\frac{1}{3}\\right]\\right]$"
      ],
      "text/plain": [
       "[[Rational(1, 3), Rational(1, 3), Rational(1, 3)], [Rational(1, 3), Rational(1, 3), Rational(1, 3)]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbt.nash.lcp_solve(gbt_matrix_rps_game).equilibria[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966e7e3f",
   "metadata": {},
   "source": [
    "We can use OpenSpiel's dynamics module to demonstrate evolutionary game theory dynamics, or \"replicator dynamics\", which models how strategy population frequencies change over time based on relative fitness/payoffs.\n",
    "\n",
    "Let's start with an initial population that is not at equilibrium, but weighted quite heavily towards scissors with proportions: 20% Rock, 20% Paper, 60% Scissors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf1acdeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.08, -0.08,  0.  ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dyn = dynamics.SinglePopulationDynamics(matrix_rps_payoffs, dynamics.replicator)\n",
    "x = np.array([0.2, 0.2, 0.6])\n",
    "dyn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa382753",
   "metadata": {},
   "source": [
    "`dyn(x)` calculates the rate of change (derivative) for each strategy in the current population state and returns how fast each strategy's frequency is changing.\n",
    "\n",
    "In replicator dynamics, strategies that perform better than average will increase in frequency, while strategies performing worse will decrease. Since Scissors beats Paper but loses to Rock, and this population has few Rock players, we'd expect:\n",
    "\n",
    "- Scissors frequency might decrease (vulnerable to Rock)\n",
    "- Rock frequency might increase (beats the abundant Scissors)\n",
    "- Paper frequency might decrease (loses to abundant Scissors)\n",
    "\n",
    "This is part of the evolutionary path toward the Nash equilibrium where all three strategies have equal frequency (1/3 each) in Rock-Paper-Scissors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9a352c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17411743 0.45787641 0.36800616]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0.25, 0.25, 0.5])\n",
    "alpha = 0.01\n",
    "for i in range(10000):\n",
    "    x += alpha * dyn(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Extensive form example: Silly1111 Poker -->\n",
    "\n",
    "<!-- Silly poker is a variant imperfect information one-card poker game introduced in tutorial 3, but in which there are 3 possible cards (J, Q, K) instead of 2. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12f6330",
   "metadata": {},
   "source": [
    "## Extensive form example: Tiny Hanabi\n",
    "\n",
    "For extensive form games, OpenSpiel can export to the EFG format used by Gambit. Here we demonstrate this with Tiny Hanabi, loaded from the OpenSpiel [game library](https://openspiel.readthedocs.io/en/latest/games.html).\n",
    "\n",
    "\n",
    "Note: as of OpenSpiel `1.6.1`, many of the games in the game library do not produce correct EFG exports. For example, Kuhn Poker EFG export did not produce a valid `.efg` file for Gambit, giving the error:\n",
    "\n",
    "```\n",
    "ValueError: Parse error in game file: Probabilities must sum to exactly one\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02a42600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EFG 2 R \"tiny_hanabi()\" { \"Pl0\" \"Pl1\" } \\nc \"\" 1 \"\" { \"d0\" 0.5000000000000000 \"d1\" 0.5000000000000000  } 0\\n c \"p0:d0\" 2 \"\" { \"d0\" 0.5000000000000000 \"d1\" 0.5000000000000000  } 0\\n  p \"\" 1 1 \"\" { \"p0a0\" \"p0a1\" \"p0a2\"  } 0\\n   p \"\" 2 1 \"\" { \"p1a0\" \"p1a1\" \"p1a2\"  } 0\\n    t \"\" 1 \"\" { 10.0 10.0 }\\n    t \"\" 2 \"\" { 0.0 0.0 }\\n    t \"\" 3 \"\" { 0.0 0.0 }\\n   p \"\" 2 2 \"\" { \"p1a0\" \"p1a1\" \"p1a2\"  } 0\\n    t \"\" 4 \"\" { 4.0 4.0 }\\n    t \"\" 5 \"\" { 8.0 8.0 }\\n    t \"\" 6 \"\" { 4.0 4.0 }\\n   p \"\" 2 3 \"\" { \"p1a0\" \"p1a1\" \"p1a2\"  } 0\\n    t \"\" 7 \"\" { 10.0 10.0 }\\n    t \"\" 8 \"\" { 0.0 0.0 }\\n    t \"\" 9 \"\" { 0.0 0.0 }\\n  p \"\" 1 1 \"\" { \"p0a0\" \"p0a1\" \"p0a2\"  } 0\\n   p \"\" 2 4 \"\" { \"p1a0\" \"p1a1\" \"p1a2\"  } 0\\n    t \"\" 10 \"\" { 0.0 0.0 }\\n    t \"\" 11 \"\" { 0.0 0.0 }\\n    t \"\" 12 \"\" { 10.0 10.0 }\\n   p \"\" 2 5 \"\" { \"p1a0\" \"p1a1\" \"p1a2\"  } 0\\n    t \"\" 13 \"\" { 4.0 4.0 }\\n    t \"\" 14 \"\" { 8.0 8.0 }\\n    t \"\" 15 \"\" { 4.0 4.0 }\\n   p \"\" 2 6 \"\" { \"p1a0\" \"p1a1\" \"p1a2\"  } 0\\n    t \"\" 16 \"\" { 0.0 0.0 }\\n    t \"\" 17 \"\" { 0.0 0.0 }\\n    t \"\" 18 \"\" { 10.0 10.0 }\\n c \"p0:d1\" 3 \"\" { \"d0\" 0.5000000000000000 \"d1\" 0.5000000000000000  } 0\\n  p \"\" 1 2 \"\" { \"p0a0\" \"p0a1\" \"p0a2\"  } 0\\n   p \"\" 2 1 \"\" { \"p1a0\" \"p1a1\" \"p1a2\"  } 0\\n    t \"\" 19 \"\" { 0.0 0.0 }\\n    t \"\" 20 \"\" { 0.0 0.0 }\\n    t \"\" 21 \"\" { 10.0 10.0 }\\n   p \"\" 2 2 \"\" { \"p1a0\" \"p1a1\" \"p1a2\"  } 0\\n    t \"\" 22 \"\" { 4.0 4.0 }\\n    t \"\" 23 \"\" { 8.0 8.0 }\\n    t \"\" 24 \"\" { 4.0 4.0 }\\n   p \"\" 2 3 \"\" { \"p1a0\" \"p1a1\" \"p1a2\"  } 0\\n    t \"\" 25 \"\" { 0.0 0.0 }\\n    t \"\" 26 \"\" { 0.0 0.0 }\\n    t \"\" 27 \"\" { 0.0 0.0 }\\n  p \"\" 1 2 \"\" { \"p0a0\" \"p0a1\" \"p0a2\"  } 0\\n   p \"\" 2 4 \"\" { \"p1a0\" \"p1a1\" \"p1a2\"  } 0\\n    t \"\" 28 \"\" { 10.0 10.0 }\\n    t \"\" 29 \"\" { 0.0 0.0 }\\n    t \"\" 30 \"\" { 0.0 0.0 }\\n   p \"\" 2 5 \"\" { \"p1a0\" \"p1a1\" \"p1a2\"  } 0\\n    t \"\" 31 \"\" { 4.0 4.0 }\\n    t \"\" 32 \"\" { 8.0 8.0 }\\n    t \"\" 33 \"\" { 4.0 4.0 }\\n   p \"\" 2 6 \"\" { \"p1a0\" \"p1a1\" \"p1a2\"  } 0\\n    t \"\" 34 \"\" { 10.0 10.0 }\\n    t \"\" 35 \"\" { 0.0 0.0 }\\n    t \"\" 36 \"\" { 0.0 0.0 }\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops_hanabi_game = pyspiel.load_game(\"tiny_hanabi\")\n",
    "efg_hanabi_game = export_gambit(ops_hanabi_game)\n",
    "efg_hanabi_game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa354c9f",
   "metadata": {},
   "source": [
    "Now let's load the EFG in Gambit (bear in mind that Gambit's `read_efg` function expects a file like object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a534e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Game(title='tiny_hanabi()')"
      ],
      "text/plain": [
       "Game(title='tiny_hanabi()')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbt_hanabi_game = gbt.read_efg(StringIO(efg_hanabi_game))\n",
    "gbt_hanabi_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34508bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pl0\n",
      "Pl1\n"
     ]
    }
   ],
   "source": [
    "for p in gbt_hanabi_game.players:\n",
    "    print(p.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ec19b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\left[\\left[\\left[0,0,1\\right],\\left[0,1,0\\right]\\right],\\left[\\left[0,0,1\\right],\\left[0,1,0\\right],\\left[1,0,0\\right],\\left[0,0,1\\right],\\left[0,1,0\\right],\\left[0,0,1\\right]\\right]\\right]$"
      ],
      "text/plain": [
       "[[[Rational(0, 1), Rational(0, 1), Rational(1, 1)], [Rational(0, 1), Rational(1, 1), Rational(0, 1)]], [[Rational(0, 1), Rational(0, 1), Rational(1, 1)], [Rational(0, 1), Rational(1, 1), Rational(0, 1)], [Rational(1, 1), Rational(0, 1), Rational(0, 1)], [Rational(0, 1), Rational(0, 1), Rational(1, 1)], [Rational(0, 1), Rational(1, 1), Rational(0, 1)], [Rational(0, 1), Rational(0, 1), Rational(1, 1)]]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eqm = gbt.nash.lcp_solve(gbt_hanabi_game).equilibria[0]\n",
    "eqm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51406cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pygambit.gambit.MixedBehaviorProfileRational"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(eqm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b45ef68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\left[\\left[0,0,1\\right],\\left[0,1,0\\right]\\right]$"
      ],
      "text/plain": [
       "[[Rational(0, 1), Rational(0, 1), Rational(1, 1)], [Rational(0, 1), Rational(1, 1), Rational(0, 1)]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eqm['Pl0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae9fc7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At information set 0, Player 0 plays action 0 with probability: 0 and action 1 with probability: 0 and action 2 with probability: 1\n",
      "At information set 1, Player 0 plays action 0 with probability: 0 and action 1 with probability: 1 and action 2 with probability: 0\n"
     ]
    }
   ],
   "source": [
    "for infoset, mixed_action in eqm[\"Pl0\"].mixed_actions():\n",
    "    print(\n",
    "        f\"At information set {infoset.number}, \"\n",
    "        f\"Player 0 plays action 0 with probability: {mixed_action['p0a0']}\"\n",
    "        f\" and action 1 with probability: {mixed_action['p0a1']}\"\n",
    "        f\" and action 2 with probability: {mixed_action['p0a2']}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8528e1bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\left[\\left[0,0,1\\right],\\left[0,1,0\\right],\\left[1,0,0\\right],\\left[0,0,1\\right],\\left[0,1,0\\right],\\left[0,0,1\\right]\\right]$"
      ],
      "text/plain": [
       "[[Rational(0, 1), Rational(0, 1), Rational(1, 1)], [Rational(0, 1), Rational(1, 1), Rational(0, 1)], [Rational(1, 1), Rational(0, 1), Rational(0, 1)], [Rational(0, 1), Rational(0, 1), Rational(1, 1)], [Rational(0, 1), Rational(1, 1), Rational(0, 1)], [Rational(0, 1), Rational(0, 1), Rational(1, 1)]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eqm['Pl1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2965aed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At information set 0, Player 1 plays action 0 with probability: 0 and action 1 with probability: 0 and action 2 with probability: 1\n",
      "At information set 1, Player 1 plays action 0 with probability: 0 and action 1 with probability: 1 and action 2 with probability: 0\n",
      "At information set 2, Player 1 plays action 0 with probability: 1 and action 1 with probability: 0 and action 2 with probability: 0\n",
      "At information set 3, Player 1 plays action 0 with probability: 0 and action 1 with probability: 0 and action 2 with probability: 1\n",
      "At information set 4, Player 1 plays action 0 with probability: 0 and action 1 with probability: 1 and action 2 with probability: 0\n",
      "At information set 5, Player 1 plays action 0 with probability: 0 and action 1 with probability: 0 and action 2 with probability: 1\n"
     ]
    }
   ],
   "source": [
    "for infoset, mixed_action in eqm[\"Pl1\"].mixed_actions():\n",
    "    print(\n",
    "        f\"At information set {infoset.number}, \"\n",
    "        f\"Player 1 plays action 0 with probability: {mixed_action['p1a0']}\"\n",
    "        f\" and action 1 with probability: {mixed_action['p1a1']}\"\n",
    "        f\" and action 2 with probability: {mixed_action['p1a2']}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d628c0d5",
   "metadata": {},
   "source": [
    "Let's now train 2 agents using independent Q-learning on Tiny Hanabi, and play them against eachother.\n",
    "\n",
    "We can compare the learned strategies played to the equilibrium strategies computed by Gambit.\n",
    "\n",
    "First let's open the RL environment for Tiny Hanabi and create the agents, one for each player (2 players in this case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e72c924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the environment\n",
    "env = rl_environment.Environment(\"tiny_hanabi\")\n",
    "num_players = env.num_players\n",
    "num_actions = env.action_spec()[\"num_actions\"]\n",
    "\n",
    "# Create the agents\n",
    "agents = [\n",
    "    tabular_qlearner.QLearner(player_id=idx, num_actions=num_actions)\n",
    "    for idx in range(num_players)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf9eea4",
   "metadata": {},
   "source": [
    "Now we can train the Q-learning agents in self-play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53547263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 0\n",
      "Episodes: 1000\n",
      "Episodes: 2000\n",
      "Episodes: 3000\n",
      "Episodes: 4000\n",
      "Episodes: 5000\n",
      "Episodes: 6000\n",
      "Episodes: 7000\n",
      "Episodes: 8000\n",
      "Episodes: 9000\n",
      "Episodes: 10000\n",
      "Episodes: 11000\n",
      "Episodes: 12000\n",
      "Episodes: 13000\n",
      "Episodes: 14000\n",
      "Episodes: 15000\n",
      "Episodes: 16000\n",
      "Episodes: 17000\n",
      "Episodes: 18000\n",
      "Episodes: 19000\n",
      "Episodes: 20000\n",
      "Episodes: 21000\n",
      "Episodes: 22000\n",
      "Episodes: 23000\n",
      "Episodes: 24000\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for cur_episode in range(25000):\n",
    "  if cur_episode % 1000 == 0:\n",
    "    print(f\"Episodes: {cur_episode}\")\n",
    "  time_step = env.reset()\n",
    "  while not time_step.last():\n",
    "    player_id = time_step.observations[\"current_player\"]\n",
    "    agent_output = agents[player_id].step(time_step)\n",
    "    time_step = env.step([agent_output.action])\n",
    "  # Episode is over, step all agents with final info state.\n",
    "  for agent in agents:\n",
    "    agent.step(time_step)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d71bc733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "p0:d0 p1:d0\n",
      "Agent 0 chooses p0a2\n",
      "\n",
      "p0:d0 p1:d0 p0:a2\n",
      "Agent 1 chooses p1a0\n",
      "\n",
      "p0:d0 p1:d0 p0:a2 p1:a0\n",
      "[10.0, 10.0]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Q-learning agent against another\n",
    "eval_agents = [agents[0], agents[1]]\n",
    "\n",
    "time_step = env.reset()\n",
    "while not time_step.last():\n",
    "  print(\"\")\n",
    "  print(env.get_state)\n",
    "  player_id = time_step.observations[\"current_player\"]\n",
    "  # Note the evaluation flag. A Q-learner will set epsilon=0 here.\n",
    "  agent_output = eval_agents[player_id].step(time_step, is_evaluation=True)\n",
    "  print(f\"Agent {player_id} chooses {env.get_state.action_to_string(agent_output.action)}\")\n",
    "  time_step = env.step([agent_output.action])\n",
    "\n",
    "print(\"\")\n",
    "print(env.get_state)\n",
    "print(time_step.rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e9b174",
   "metadata": {},
   "source": [
    "Is this one of the equilibrium strategies computed by Gambit?\n",
    "\n",
    "When I ran the above I got the final game state `p0:d0 p1:d0 p0:a2 p1:a0` with payoffs `[10.0, 10.0]`.\n",
    "\n",
    "The node `p0:d0 p1:d0` is part of player 0's information set 0. p0 picks a2 which matches the first equilibrium strategy in `eqm['Pl0']` where action `p0a2` is played with probability 1.0. This put's player 1 in their information set 2, and player 1 picks action 0, which is consistent with `eqm['Pl1']` where action `p1a0` is played with probability 1.0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gbt_pygraphviz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
